{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c50f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "embedding_models = {\n",
    "\t\"Legacy_1\": \"models/embedding-001\",\n",
    "\t\"Legacy_2\": \"models/text-embedding-004\",\n",
    "\t\"Current\": \"models/gemini-embedding-001\",\n",
    "}\n",
    "\n",
    "chat_models = {\n",
    "\t\"FLASH_LATEST\": \"gemini-2.5-flash-preview-09-2025\",\n",
    "\t\"PRO\": \"gemini-2.5-pro\",\n",
    "}\n",
    "\n",
    "\n",
    "class GeminiModel:\n",
    "\tDEFAULT_CHAT_MODEL = chat_models[\"FLASH_LATEST\"]\n",
    "\tDEFAULT_EMBEDDING_MODEL = embedding_models[\"Current\"]\n",
    "\n",
    "\tdef __init__(self, *, api_key=None):\n",
    "\t\tif api_key is None:\n",
    "\t\t\tload_dotenv()\n",
    "\t\t\tGOOGLE_API_KEY = self.getEnvAPIKey()\n",
    "\t\telse:\n",
    "\t\t\tGOOGLE_API_KEY = api_key\n",
    "\t\tself.client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "\tdef getEnvAPIKey(self):\n",
    "\t\tload_dotenv()\n",
    "\t\treturn os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "\tdef startChat(self, model_name=None):\n",
    "\n",
    "\t\tif model_name is None:\n",
    "\t\t\tmodel_name = self.DEFAULT_CHAT_MODEL\n",
    "\n",
    "\t\tchat = self.client.chats.create(model=model_name)\n",
    "\t\treturn chat\n",
    "\n",
    "\tdef send_prompt(self, chat, prompt):\n",
    "\t\tresponse = chat.send_message(prompt)\n",
    "\t\treturn response.text\n",
    "\n",
    "\tdef getSemanticEmbedding(self, semantic_datum, *, model_name=None, task_type=None):\n",
    "\t\tif task_type is None:\n",
    "\t\t\ttask_type = \"SEMANTIC_SIMILARITY\"\n",
    "\t\tif model_name is None:\n",
    "\t\t\tmodel_name = self.DEFAULT_EMBEDDING_MODEL\n",
    "\t\tresult = self.client.models.embed_content(\n",
    "\t\t\tmodel=model_name,\n",
    "\t\t\tcontents=semantic_datum,\n",
    "\t\t\tconfig=types.EmbedContentConfig(task_type=task_type),\n",
    "\t\t)\n",
    "\t\treturn result.embeddings[0].values\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef preprocessStatement(statement):\n",
    "\t\tprefix = \"Does the privacy policy affirm that \"\n",
    "\t\tprocessed_text = (statement[len(prefix) :].capitalize())[:-1] + \".\"\n",
    "\t\treturn processed_text\n",
    "\n",
    "\t@staticmethod\n",
    "\tdef preprocessStatement2(statement):\n",
    "\t\tprefix = \"Does the privacy policy affirm\"\n",
    "\t\treplacement = \"The privacy policy affirms\"\n",
    "\t\t# processed_text = (statement[len(prefix) :].capitalize())[:-1] + \".\"\n",
    "\t\tprocessed_text = (\"The privacy policy affirms\" + statement[len(prefix) :])[:-1] + \".\"\n",
    "\n",
    "\t\treturn processed_text\n",
    "\n",
    "\n",
    "question_1 = \"Does the privacy policy affirm that personal data transfers are automatically consented to by using the service?\"\n",
    "question_1_prime = \"Does the privacy policy affirm that user data transfers are automatically consented to by using the service?\"\n",
    "question_2 = \"Does the privacy policy affirm that personal data processing is automatically consented to by using the service?\"\n",
    "\n",
    "s_1 = GeminiModel.preprocessStatement(question_1)\n",
    "s_1_p = GeminiModel.preprocessStatement(question_1_prime)\n",
    "s_2 = GeminiModel.preprocessStatement(question_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a49f984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 vs 1 prime: 0.9920240458129393\n",
      "1 vs 2: 0.970932779302992\n",
      "delta = 0.021091266509947304\n",
      "statement 1 vs 1 prime: 0.9873116243207628\n",
      "statement 1 vs 2: 0.9590774326955188\n",
      "delta = 0.028234191625243987\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "task_type = \"None\"\n",
    "\n",
    "\n",
    "def process_sim(emb_a, emb_b):\n",
    "\tarr_1 = np.array(emb_a)\n",
    "\tarr_2 = np.array(emb_b)\n",
    "\tdot_product = np.dot(arr_1, arr_2)\n",
    "\tnorm1 = np.linalg.norm(arr_1)\n",
    "\tnorm2 = np.linalg.norm(arr_2)\n",
    "\tsimilarity_score = dot_product / (norm1 * norm2)\n",
    "\treturn similarity_score\n",
    "\n",
    "\n",
    "q_1_embed = model.getSemanticEmbedding(question_1)\n",
    "q_1_prime_embed = model.getSemanticEmbedding(question_1_prime)\n",
    "q_2_embed = model.getSemanticEmbedding(question_2)\n",
    "\n",
    "sim_a = process_sim(q_1_embed, q_1_prime_embed)\n",
    "sim_b = process_sim(q_1_embed, q_2_embed)\n",
    "print(f\"1 vs 1 prime: {sim_a}\")\n",
    "print(f\"1 vs 2: {sim_b}\")\n",
    "print(f\"delta = {sim_a-sim_b}\")\n",
    "\n",
    "s_1_embed = model.getSemanticEmbedding(s_1)\n",
    "s_1_prime_embed = model.getSemanticEmbedding(s_1_p)\n",
    "s2_embed = model.getSemanticEmbedding(s_2)\n",
    "sim_c = process_sim(s_1_embed, s_1_prime_embed)\n",
    "sim_d = process_sim(s_1_embed, s2_embed)\n",
    "print(f\"statement 1 vs 1 prime: {sim_c}\")\n",
    "print(f\"statement 1 vs 2: {sim_d}\")\n",
    "print(f\"delta = {sim_c-sim_d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ea5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from markdownify import markdownify as md\n",
    "# import re\n",
    "# import datetime\n",
    "# import hashlib\n",
    "\n",
    "# current_date = datetime.datetime.now().__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d7ed66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # String methods\n",
    "\n",
    "\n",
    "# def isInString(string, substring):\n",
    "# \treturn substring in string\n",
    "\n",
    "\n",
    "# def getSubstringIndices(string, substring):\n",
    "# \tstart_index = string.find(substring)\n",
    "# \tend_index = start_index + len(substring)\n",
    "# \treturn (start_index, end_index)\n",
    "\n",
    "\n",
    "# # def getHash(data):\n",
    "# # \t# return hash(data)\n",
    "# # \treturn hashlib.sha256(data.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadf1821",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51346acb",
   "metadata": {},
   "source": [
    "policy_breakdown = {}\n",
    "\n",
    "policy_template = {\n",
    "\t\"policy_name:string\": {\n",
    "\t\t\"version_hash:string\": {\"date\": \"\", \"policy_md\": \"string\", \"policy_breakdown\": [\"\"]}\n",
    "\t}\n",
    "}\n",
    "question_relation: {\n",
    "policy_name,\n",
    "version_hash,\n",
    "relevant_substring?,\n",
    "relevant_substring_idx?,\n",
    "}\n",
    "question_data needs to include:\n",
    "\t- question:string\n",
    "\t- origin:question_relation\n",
    "\t- other_policies:question_relation[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38726882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Markdown Methods\n",
    "\n",
    "\n",
    "def splitMarkdown(markdown_text):\n",
    "\theading_pattern = r\"^#{1,6}\\s+.*\"\n",
    "\tparts = re.split(heading_pattern, markdown_text, flags=re.MULTILINE)\n",
    "\tcontent_list = [part.strip() for part in parts[1:] if part.strip()]\n",
    "\treturn content_list\n",
    "\n",
    "\n",
    "def removePreamble(markdown_text):\n",
    "\tpattern = r\"\\A.*?(?=^#\\s)\"\n",
    "\tcleaned_text = re.sub(pattern, \"\", markdown_text, flags=re.DOTALL | re.MULTILINE)\n",
    "\treturn cleaned_text\n",
    "\n",
    "\n",
    "MARKDOWN_LINK_PATTERN = re.compile(r\"(\\[.*?\\])\\((.*?)\\)\")\n",
    "URL_PLACEHOLDER = \"(DYNAMIC_URL_REMOVED)\"\n",
    "\n",
    "\n",
    "def normalize_markdown_links(markdown_text):\n",
    "\n",
    "\tdef replacer(match):\n",
    "\t\treturn match.group(1) + URL_PLACEHOLDER\n",
    "\n",
    "\tnormalized_text = MARKDOWN_LINK_PATTERN.sub(replacer, markdown_text)\n",
    "\treturn normalized_text\n",
    "\n",
    "\n",
    "def getHash(data):\n",
    "\n",
    "\tcleaned_data = normalize_markdown_links(data)\n",
    "\n",
    "\treturn hashlib.sha256(cleaned_data.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19dc1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL Methods\n",
    "\n",
    "# url = \"https://openai.com/policies/privacy-policy/\"\n",
    "# url = \"https://www.gemini.com/en-SG/legal/privacy-policy\"\n",
    "# url = \"https://www.anthropic.com/legal/privacy\"\n",
    "\n",
    "data_source = {\n",
    "\t\"gemini\": \"https://www.gemini.com/en-SG/legal/privacy-policy\",\n",
    "\t\"openai\": \"https://openai.com/policies/privacy-policy/\",\n",
    "\t\"anthropic\": \"https://www.anthropic.com/legal/privacy\",\n",
    "}\n",
    "\n",
    "\n",
    "def extractContent(url, headers=None):\n",
    "\tif headers is None:\n",
    "\t\theaders = {\n",
    "\t\t\t\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "\t\t}\n",
    "\n",
    "\t\tresponse = requests.get(url, headers=headers, timeout=10)\n",
    "\t\tresponse.raise_for_status()\n",
    "\t\thtml_content = response.text\n",
    "\n",
    "\t\tsoup = BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "\t\tmain_content_element = soup.find(\"main\")\n",
    "\n",
    "\t\treturn main_content_element\n",
    "\n",
    "\n",
    "def extractMarkdown(main_content):\n",
    "\treturn md(str(main_content), heading_style=\"ATX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33264f65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdae5b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c870b80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_policy_data = {\"policy_markdown\": \"\", \"fetch_date\": \"\", \"chunks\": []}\n",
    "\n",
    "chunk = {\"\": \"\"}\n",
    "policy_breakdowns = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b63d4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     27\u001b[39m \t\t_processPolicy(markdown_content, policy_name, policy_url, _hash)\n\u001b[32m     28\u001b[39m \t\u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43mprocessPolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_breakdowns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43manthropic\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.anthropic.com/legal/privacy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# extractContent(\"https://www.anthropic.com/legal/privacy\")\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mprocessPolicy\u001b[39m\u001b[34m(all_policy_data, policy_name, policy_url)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprocessPolicy\u001b[39m(all_policy_data, policy_name, policy_url):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \tmain_content = \u001b[43mextractContent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \tmarkdown_content = removePreamble(extractMarkdown(main_content))\n\u001b[32m     21\u001b[39m \t_hash = getHash(markdown_content)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mextractContent\u001b[39m\u001b[34m(url, headers)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m headers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     16\u001b[39m \theaders = {\n\u001b[32m     17\u001b[39m \t\t\u001b[33m\"\u001b[39m\u001b[33mUser-Agent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mMozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     18\u001b[39m \t}\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \tresponse = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \tresponse.raise_for_status()\n\u001b[32m     22\u001b[39m \thtml_content = response.text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/requests/api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/requests/api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AICompatibleWEB/.venv/lib/python3.13/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    562\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    568\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1428\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1429\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1432\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    333\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/http/client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    294\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.5/Frameworks/Python.framework/Versions/3.13/lib/python3.13/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Policy Methods\n",
    "\n",
    "\n",
    "def _processPolicy(markdown_content, policy_name, policy_url, policy_hash):\n",
    "\tdata = _policy_data.copy()\n",
    "\tdata[\"policy_markdown\"] = markdown_content\n",
    "\tdata[\"fetch_date\"] = datetime.datetime.now().__str__()\n",
    "\tchunks = []\n",
    "\tproto_chunks = splitMarkdown(markdown_content)\n",
    "\tfor i in proto_chunks:\n",
    "\t\tchunks.append({getHash(i): i})\n",
    "\n",
    "\tdata[\"chunks\"] = chunks\n",
    "\n",
    "\tpolicy_breakdowns[policy_name][policy_hash] = data\n",
    "\n",
    "\n",
    "def processPolicy(all_policy_data, policy_name, policy_url):\n",
    "\tmain_content = extractContent(policy_url)\n",
    "\tmarkdown_content = removePreamble(extractMarkdown(main_content))\n",
    "\t_hash = getHash(markdown_content)\n",
    "\n",
    "\tif not (policy_name in all_policy_data):\n",
    "\t\tall_policy_data[policy_name] = {}\n",
    "\n",
    "\tif not (_hash in all_policy_data[policy_name]):\n",
    "\t\t_processPolicy(markdown_content, policy_name, policy_url, _hash)\n",
    "\treturn\n",
    "\n",
    "\n",
    "processPolicy(policy_breakdowns, \"anthropic\", \"https://www.anthropic.com/legal/privacy\")\n",
    "# extractContent(\"https://www.anthropic.com/legal/privacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecedee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "_GOOGLE_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "# client = genai.Client(api_key=_GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818ba7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from model_parameters import DEFAULT_MODEL_NAME\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "_GOOGLE_API_KEY = os.environ.get(\"GEMINI_API_KEY\")\n",
    "\n",
    "client = genai.Client(api_key=_GOOGLE_API_KEY)\n",
    "\n",
    "\n",
    "def send_prompt(chat, prompt):\n",
    "\tresponse = chat.send_message(prompt)\n",
    "\treturn response.text\n",
    "\n",
    "\n",
    "def startChat(GOOGLE_API_KEY=None, model_name=None):\n",
    "\n",
    "\tif GOOGLE_API_KEY is None:\n",
    "\t\tGOOGLE_API_KEY = _GOOGLE_API_KEY\n",
    "\tif model_name is None:\n",
    "\t\tmodel_name = DEFAULT_MODEL_NAME\n",
    "\n",
    "\tchat = client.chats.create(model=model_name)\n",
    "\treturn chat\n",
    "\n",
    "\n",
    "def f():\n",
    "\tchat = startChat()\n",
    "\tresponse = send_prompt(chat, \"hello\")\n",
    "\tprint(response)\n",
    "\n",
    "\n",
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c76e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_parameters import DEFAULT_MODEL_NAME\n",
    "from _prompts import ANALYSIS_PROMPT, SUBSTRING_PROMPT\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import google.generativeai as embedding_genai\n",
    "\n",
    "from google import genai\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def send_prompt(chat, prompt):\n",
    "\tresponse = chat.send_message(prompt)\n",
    "\treturn response.text\n",
    "\n",
    "\n",
    "def startChat(GOOGLE_API_KEY=None, model_name=None):\n",
    "\tif GOOGLE_API_KEY is None:\n",
    "\t\tGOOGLE_API_KEY = _GOOGLE_API_KEY\n",
    "\tif model_name is None:\n",
    "\t\tmodel_name = DEFAULT_MODEL_NAME\n",
    "\n",
    "\tchat = client.chats.create(model=model_name)\n",
    "\treturn chat\n",
    "\n",
    "\n",
    "def _startChat(GOOGLE_API_KEY=None, model_name=None):\n",
    "\tif GOOGLE_API_KEY is None:\n",
    "\t\tGOOGLE_API_KEY = _GOOGLE_API_KEY\n",
    "\tif model_name is None:\n",
    "\t\tmodel_name = DEFAULT_MODEL_NAME\n",
    "\tclient = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "\tchat = client.chats.create(model=model_name)\n",
    "\tr = chat.send_message(\"hello\")\n",
    "\tprint(r.text)\n",
    "\treturn chat\n",
    "\n",
    "\n",
    "import google.generativeai as embedding_genai\n",
    "\n",
    "\n",
    "def getEmbedding(semantic_datum, GOOGLE_API_KEY):\n",
    "\ttry:\n",
    "\t\tembedding_genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\texcept AttributeError:\n",
    "\t\tprint(\"Please set your GEMINI_API_KEY environment variable.\")\n",
    "\n",
    "\tresult1 = embedding_genai.embed_content(\n",
    "\t\tmodel=\"models/embedding-001\", content=semantic_datum, task_type=\"SEMANTIC_SIMILARITY\"\n",
    "\t)\n",
    "\treturn np.array(result1[\"embedding\"])\n",
    "\n",
    "\n",
    "import ast\n",
    "\n",
    "policy_qs = {}\n",
    "THRESHOLD = 0.97\n",
    "\n",
    "\n",
    "def verifyResponse(response):\n",
    "\tif response.startswith(\"```json\") and response.endswith(\"```\"):\n",
    "\t\ttry:\n",
    "\t\t\treturn ast.literal_eval(response[7:-3])\n",
    "\t\texcept:\n",
    "\t\t\tprint(response[7:-3])\n",
    "\t\t\traise\n",
    "\treturn None\n",
    "\n",
    "\n",
    "def getQuestions(subsection):\n",
    "\tchat = startChat()\n",
    "\t_ = send_prompt(chat, ANALYSIS_PROMPT)\n",
    "\tresponse = send_prompt(chat, str(subsection))\n",
    "\tproto_questions = verifyResponse(response)\n",
    "\tif proto_questions == None:\n",
    "\t\treturn getQuestions(subsection)\n",
    "\treturn proto_questions\n",
    "\n",
    "\n",
    "def getSubstrings(questions):\n",
    "\tchat = startChat()\n",
    "\t_ = send_prompt(chat, SUBSTRING_PROMPT)\n",
    "\tresponse = send_prompt(chat, f\"```{str(subsection)}```\")\n",
    "\tproto_strings = verifyResponse(response)\n",
    "\tif proto_strings == None:\n",
    "\t\treturn getSubstrings(subsection)\n",
    "\treturn proto_strings\n",
    "\n",
    "\n",
    "def produceQuestions(policy_hash, policy_name, policy_breakdown):\n",
    "\tfor i in policy_breakdown:\n",
    "\t\tsection = list(i.values())[0]\n",
    "\t\tproto_questions = getQuestions(section)\n",
    "\t\tfor _, w in proto_questions.items():\n",
    "\t\t\tembedding = getEmbedding(w, _GOOGLE_API_KEY)\n",
    "\t\t\tother_embeddings = list(policy_qs.keys())\n",
    "\t\t\thasSimilar = False\n",
    "\t\t\tif len(other_embeddings) > 0:\n",
    "\t\t\t\tfor e in other_embeddings:\n",
    "\t\t\t\t\tdot_product = np.dot(embedding, np.array(e))\n",
    "\t\t\t\t\tnorm1 = np.linalg.norm(embedding)\n",
    "\t\t\t\t\tnorm2 = np.linalg.norm(1)\n",
    "\t\t\t\t\tif (dot_product / (norm1 * norm2)) > THRESHOLD:\n",
    "\t\t\t\t\t\tpolicy_qs[e].update({policy_hash: section})\n",
    "\t\t\t\t\t\thasSimilar = True\n",
    "\t\t\t\t\t\tbreak\n",
    "\t\t\tif not hasSimilar:\n",
    "\t\t\t\tpolicy_qs.update({tuple(embedding): {policy_hash: section, \"question\": w}})\n",
    "\t\tprint(policy_qs)\n",
    "\t\tbreak\n",
    "\n",
    "\tqs_to_validate = []\n",
    "\tfor k, v in policy_qs.items():\n",
    "\t\tif policy_hash in v:\n",
    "\t\t\tqs_to_validate.append({\"policy_hash\": v[policy_hash], \"question\": v[\"question\"]})\n",
    "\n",
    "\tif len(qs_to_validate) > 0:\n",
    "\t\tqs_object = {}\n",
    "\n",
    "\t\tfor i, q in enumerate(qs_to_validate):\n",
    "\t\t\tqs_object[str(i)] = q[\"question\"]\n",
    "\n",
    "\t\tproto_strings = getSubstrings(qs_object)\t# need to take in snippet as arg\n",
    "\t\t# sanitise the internal `\"`\n",
    "\t\tfor k, v in proto_strings.items():\n",
    "\t\t\tif not (v in policy_breakdowns[policy_name][policy_hash][\"policy_markdown\"]):\n",
    "\t\t\t\tfor l, w in policy_qs.items():\n",
    "\t\t\t\t\tif policy_hash in w:\n",
    "\t\t\t\t\t\tpolicy_qs[l].pop(policy_hash)\n",
    "\t\t\t\traise Exception(v)\n",
    "\t\t\t\treturn produceQuestions(policy_hash, policy_name, policy_breakdown)\n",
    "\n",
    "\t# need to add substring logic\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee40a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# policy_breakdowns[\"anthropic\"]\n",
    "\n",
    "produceQuestions(\n",
    "\t\"99d2042def1972a39015ce3aabba58396d3836e653a9b424044cf35bf0a7989f\",\n",
    "\t\"anthropic\",\n",
    "\tpolicy_breakdowns[\"anthropic\"][\n",
    "\t\t\"99d2042def1972a39015ce3aabba58396d3836e653a9b424044cf35bf0a7989f\"\n",
    "\t][\"chunks\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922539f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "\t\"1\": \"Does the privacy policy affirm that it explains how the company collects, uses, discloses, and processes personal data?\",\n",
    "\t\"2\": \"Does the privacy policy affirm that it applies when the company acts as a data controller for its 'Services' and 'Commercial Services'?\",\n",
    "\t\"3\": \"Does the privacy policy affirm that using products like Claude.ai for personal use is considered one of its 'Services'?\",\n",
    "\t\"4\": \"Does the privacy policy affirm that it does not apply when the company acts as a data processor on behalf of commercial customers?\",\n",
    "\t\"5\": \"Does the privacy policy affirm that in cases where it acts as a data processor, the commercial customer is the data controller?\",\n",
    "\t\"6\": \"Does the privacy policy affirm that a separate 'Non-User Privacy Policy' provides information on how its large language models are trained?\",\n",
    "\t\"7\": \"Does the privacy policy affirm that it describes the user's privacy rights?\",\n",
    "\t\"8\": \"Does the privacy policy affirm that Section 4 ('Rights and Choices') contains more information on how to exercise privacy rights?\",\n",
    "\t\"9\": \"Does the privacy policy affirm that Section 11 contains specific provisions for users located in Canada?\",\n",
    "\t\"10\": \"Does the privacy policy affirm that Section 12 contains specific provisions for users located in Brazil?\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70026c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57806dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def saveHash(key, content):\n",
    "# \tsig = hash(content)\n",
    "# \t# save to json with key = key, v = hash\n",
    "# \t_id = sig\n",
    "# \tif _id == sig:\n",
    "# \t\treturn True\n",
    "# \t# pass\n",
    "# \treturn False\n",
    "\n",
    "\n",
    "# def extractContent(url, headers=None):\n",
    "# \tif headers is None:\n",
    "# \t\theaders = {\n",
    "# \t\t\t\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "# \t\t}\n",
    "\n",
    "# \t\tresponse = requests.get(url, headers=headers, timeout=10)\n",
    "# \t\tresponse.raise_for_status()\n",
    "# \t\thtml_content = response.text\n",
    "\n",
    "# \t\tsoup = BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "# \t\tmain_content_element = soup.find(\"main\")\n",
    "\n",
    "# \t\t_markdown_content = md(str(main_content_element), heading_style=\"ATX\")\n",
    "# \t\tmarkdown_content = removePreamble(_markdown_content)\n",
    "# \t\treturn markdown_content\n",
    "\n",
    "\n",
    "# def saveMdFile(content, name):\n",
    "# \tif not name.endswith(\".md\"):\n",
    "# \t\tname = name + \".md\"\n",
    "\n",
    "# \twith open(name, \"w\", encoding=\"utf-8\") as file:\n",
    "# \t\tfile.write(content)\n",
    "\n",
    "\n",
    "# def collatePolicy(data_source):\n",
    "# \tfor k, v in data_source.items():\n",
    "# \t\tmarkdown_content = extractContent(v)\n",
    "# \t\tif saveHash(k, markdown_content):\n",
    "# \t\t\t# Runs LLM Question analysis of content:\n",
    "# \t\t\t# adds data and new version questions to question json\n",
    "# \t\t\t# reanalyses all saved privacy policies against that # (Do at end)\n",
    "# \t\t\t# updates gui\n",
    "# \t\t\tpass\n",
    "\n",
    "# \t\tsaveMdFile(markdown_content, k)\n",
    "# \treturn splitMarkdown(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://openai.com/policies/privacy-policy/\"\n",
    "# url = \"https://www.gemini.com/en-SG/legal/privacy-policy\"\n",
    "# url = \"https://www.anthropic.com/legal/privacy\"\n",
    "\n",
    "# data_source = {\n",
    "# \t# \"gemini\": \"https://www.gemini.com/en-SG/legal/privacy-policy\",\n",
    "# \t# \"openai\": \"https://openai.com/policies/privacy-policy/\",\n",
    "# \t\"anthropic\": \"https://www.anthropic.com/legal/privacy\",\n",
    "# }\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "# from markdownify import markdownify as md\n",
    "# import re\n",
    "\n",
    "\n",
    "# def saveHash(key, content):\n",
    "# \tsig = hash(content)\n",
    "# \t# save to json with key = key, v = hash\n",
    "# \t_id = sig\n",
    "# \tif _id == sig:\n",
    "# \t\treturn True\n",
    "# \t# pass\n",
    "# \treturn False\n",
    "\n",
    "\n",
    "# def splitMarkdown(markdown_text, removeheaders=True):\n",
    "# \theading_pattern = r\"^#{1,6}\\s+.*\"\n",
    "# \tparts = re.split(heading_pattern, markdown_text, flags=re.MULTILINE)\n",
    "# \tcontent_list = [part.strip() for part in parts[1:] if part.strip()]\n",
    "# \treturn content_list\n",
    "\n",
    "\n",
    "# def removePreamble(markdown_text):\n",
    "# \tpattern = r\"\\A.*?(?=^#\\s)\"\n",
    "# \tcleaned_text = re.sub(pattern, \"\", markdown_text, flags=re.DOTALL | re.MULTILINE)\n",
    "# \treturn cleaned_text\n",
    "\n",
    "\n",
    "# def extractContent(url, headers=None):\n",
    "# \tif headers is None:\n",
    "# \t\theaders = {\n",
    "# \t\t\t\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"\n",
    "# \t\t}\n",
    "\n",
    "# \t\tresponse = requests.get(url, headers=headers, timeout=10)\n",
    "# \t\tresponse.raise_for_status()\n",
    "# \t\thtml_content = response.text\n",
    "\n",
    "# \t\tsoup = BeautifulSoup(html_content, \"lxml\")\n",
    "\n",
    "# \t\tmain_content_element = soup.find(\"main\")\n",
    "\n",
    "# \t\t_markdown_content = md(str(main_content_element), heading_style=\"ATX\")\n",
    "# \t\tmarkdown_content = removePreamble(_markdown_content)\n",
    "# \t\treturn markdown_content\n",
    "\n",
    "\n",
    "# def saveMdFile(content, name):\n",
    "# \tif not name.endswith(\".md\"):\n",
    "# \t\tname = name + \".md\"\n",
    "\n",
    "# \twith open(name, \"w\", encoding=\"utf-8\") as file:\n",
    "# \t\tfile.write(content)\n",
    "\n",
    "\n",
    "# def collatePolicy(data_source):\n",
    "# \tsplit_markdown = {}\n",
    "# \tmd = \"\"\n",
    "# \tfor k, v in data_source.items():\n",
    "# \t\tmarkdown_content = extractContent(v)\n",
    "# \t\t# if saveHash(k, markdown_content):\n",
    "# \t\t# \t# Runs LLM Question analysis of content:\n",
    "# \t\t# \t# adds data and new version questions to question json\n",
    "# \t\t# \t# reanalyses all saved privacy policies against that # (Do at end)\n",
    "# \t\t# \t# updates gui\n",
    "# \t\t# \tpass\n",
    "\n",
    "# \t\t# saveMdFile(markdown_content, k)\n",
    "# \t\tsplit_markdown[k] = splitMarkdown(markdown_content)\n",
    "# \t\tmd = markdown_content\n",
    "\n",
    "# \t# doc_str = f\"\"\"\n",
    "# \t# ```json\n",
    "# \t# {split_markdown}\n",
    "# \t# ```\n",
    "# \t# \"\"\"\n",
    "# \t# saveMdFile(doc_str, \"output\")\n",
    "# \t# return split_markdown\n",
    "\n",
    "# \treturn md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fb43d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collatePolicy(data_source)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38a0973",
   "metadata": {},
   "source": [
    "After each response pair, regex until 100% match on substrings.\n",
    "\n",
    "\n",
    "Parrelelise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8855e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import google.generativeai as genai\n",
    "# import numpy as np\n",
    "\n",
    "\n",
    "# def calculate_similarity(question1, question2):\n",
    "# \ttry:\n",
    "# \t\tgenai.configure(api_key=\"\")\n",
    "# \texcept AttributeError:\n",
    "# \t\tprint(\"Please set your GEMINI_API_KEY environment variable.\")\n",
    "\n",
    "# \tresult1 = genai.embed_content(\n",
    "# \t\tmodel=\"models/embedding-001\", content=question1, task_type=\"SEMANTIC_SIMILARITY\"\n",
    "# \t)\n",
    "# \tresult2 = genai.embed_content(\n",
    "# \t\tmodel=\"models/embedding-001\", content=question2, task_type=\"SEMANTIC_SIMILARITY\"\n",
    "# \t)\n",
    "\n",
    "# \tembedding1 = np.array(result1[\"embedding\"])\n",
    "# \tembedding2 = np.array(result2[\"embedding\"])\n",
    "\n",
    "# \tdot_product = np.dot(embedding1, embedding2)\n",
    "# \tnorm1 = np.linalg.norm(embedding1)\n",
    "# \tnorm2 = np.linalg.norm(embedding2)\n",
    "\n",
    "# \tsimilarity_score = dot_product / (norm1 * norm2)\n",
    "\n",
    "# \treturn similarity_score\n",
    "\n",
    "\n",
    "# # If threshold > 0.95 flag as similar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
