from model_parameters import DEFAULT_MODEL_NAME
from _prompts import ANALYSIS_PROMPT, SUBSTRING_PROMPT

import numpy as np

import google.generativeai as embedding_genai

from google import genai
import numpy as np


def send_prompt(chat, prompt):
	response = chat.send_message(prompt)
	return response.text


def startChat(GOOGLE_API_KEY=None, model_name=None):
	if GOOGLE_API_KEY is None:
		GOOGLE_API_KEY = _GOOGLE_API_KEY
	if model_name is None:
		model_name = DEFAULT_MODEL_NAME

	chat = client.chats.create(model=model_name)
	return chat


def _startChat(GOOGLE_API_KEY=None, model_name=None):
	if GOOGLE_API_KEY is None:
		GOOGLE_API_KEY = _GOOGLE_API_KEY
	if model_name is None:
		model_name = DEFAULT_MODEL_NAME
	client = genai.Client(api_key=GOOGLE_API_KEY)

	chat = client.chats.create(model=model_name)
	r = chat.send_message("hello")
	print(r.text)
	return chat


def getEmbedding(semantic_datum, GOOGLE_API_KEY):
	try:
		embedding_genai.configure(api_key=GOOGLE_API_KEY)
	except AttributeError:
		print("Please set your GEMINI_API_KEY environment variable.")

	result1 = embedding_genai.embed_content(
		model="models/embedding-001", content=semantic_datum, task_type="SEMANTIC_SIMILARITY"
	)
	return np.array(result1["embedding"])


import ast

policy_qs = {}
THRESHOLD = 0.97


def verifyResponse(response):
	if response.startswith("```json") and response.endswith("```"):
		try:
			return ast.literal_eval(response[7:-3])
		except:
			print(response[7:-3])
			raise
	return None


def getQuestions(subsection):
	chat = startChat()
	_ = send_prompt(chat, ANALYSIS_PROMPT)
	response = send_prompt(chat, str(subsection))
	proto_questions = verifyResponse(response)
	if proto_questions == None:
		return getQuestions(subsection)
	return proto_questions


def getSubstrings(questions):
	chat = startChat()
	_ = send_prompt(chat, SUBSTRING_PROMPT)
	response = send_prompt(chat, f"```{str(subsection)}```")
	proto_strings = verifyResponse(response)
	if proto_strings == None:
		return getSubstrings(subsection)
	return proto_strings


def produceQuestions(policy_hash, policy_name, policy_breakdown):
	for i in policy_breakdown:
		section = list(i.values())[0]
		proto_questions = getQuestions(section)
		for _, w in proto_questions.items():
			embedding = getEmbedding(w, _GOOGLE_API_KEY)
			other_embeddings = list(policy_qs.keys())
			hasSimilar = False
			if len(other_embeddings) > 0:
				for e in other_embeddings:
					dot_product = np.dot(embedding, np.array(e))
					norm1 = np.linalg.norm(embedding)
					norm2 = np.linalg.norm(1)
					if (dot_product / (norm1 * norm2)) > THRESHOLD:
						policy_qs[e].update({policy_hash: section})
						hasSimilar = True
						break
			if not hasSimilar:
				policy_qs.update({tuple(embedding): {policy_hash: section, "question": w}})
		print(policy_qs)
		break

	qs_to_validate = []
	for k, v in policy_qs.items():
		if policy_hash in v:
			qs_to_validate.append({"policy_hash": v[policy_hash], "question": v["question"]})

	if len(qs_to_validate) > 0:
		qs_object = {}

		for i, q in enumerate(qs_to_validate):
			qs_object[str(i)] = q["question"]

		proto_strings = getSubstrings(qs_object)	# need to take in snippet as arg
		# sanitise the internal `"`
		for k, v in proto_strings.items():
			if not (v in policy_breakdowns[policy_name][policy_hash]["policy_markdown"]):
				for l, w in policy_qs.items():
					if policy_hash in w:
						policy_qs[l].pop(policy_hash)
				raise Exception(v)
				return produceQuestions(policy_hash, policy_name, policy_breakdown)

	# need to add substring logic
	return
