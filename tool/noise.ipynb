{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dd12b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.covariance import LedoitWolf\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import concurrent.futures\n",
    "from itertools import product, combinations\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Existing Helper Functions (Dependencies)\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "def getMahalanobisDistances(vectors_a, vectors_b):\n",
    "\t# Mahalanobis helper kept in snake_case internally\n",
    "\tnorms = np.linalg.norm(vectors_a, axis=1, keepdims=True)\n",
    "\tcleaned_vectors = vectors_a / (norms + 1e-10)\n",
    "\n",
    "\tlw = LedoitWolf()\n",
    "\tlw.fit(cleaned_vectors)\t# assumption vectors_a=vectors_b\n",
    "\tprecision_matrix = lw.precision_\n",
    "\n",
    "\tdist_matrix = cdist(\n",
    "\t\tcleaned_vectors, cleaned_vectors, metric=\"mahalanobis\", VI=precision_matrix\n",
    "\t)\n",
    "\treturn dist_matrix, precision_matrix\n",
    "\n",
    "\n",
    "Distance_Processors = {\n",
    "\t\"cosine\": lambda emb_a, emb_b: 1.0\n",
    "\t- (emb_a @ emb_b.T)\n",
    "\t/ (\n",
    "\t\tnp.linalg.norm(emb_a, axis=1, keepdims=True)\n",
    "\t\t@ np.linalg.norm(emb_b, axis=1, keepdims=True).T\n",
    "\t\t+ 1e-10\n",
    "\t),\n",
    "\t\"l1\": lambda emb_a, emb_b: np.sum(np.abs(emb_a[..., np.newaxis] - emb_b.T), axis=1),\n",
    "\t\"l2\": lambda emb_a, emb_b: np.linalg.norm(emb_a[..., np.newaxis] - emb_b.T, axis=1),\n",
    "\t\"dot\": lambda emb_a, emb_b: emb_a @ emb_b.T,\n",
    "\t\"mahalanobis\": lambda emb_a, emb_b: getMahalanobisDistances(emb_a, emb_b),\n",
    "}\n",
    "\n",
    "\n",
    "def _prepareModelArtifact(\n",
    "\traw_vectors,\n",
    "\tsemantic_data,\n",
    "\ttruncation_dim=256,\n",
    "\tdistance_metric=\"mahalanobis\",\n",
    "\tdebug=True,\n",
    "):\n",
    "\t# 1. Truncation\n",
    "\tdata_matrix = np.array(raw_vectors)\n",
    "\tinput_dim = data_matrix.shape[1]\n",
    "\n",
    "\tif input_dim < truncation_dim and debug:\n",
    "\t\tprint(\n",
    "\t\t\tf\"Warning: Vector dimension ({input_dim}) is smaller than truncation limit ({truncation_dim}). Proceeding without truncation.\"\n",
    "\t\t)\n",
    "\n",
    "\tdata_truncated = data_matrix[:, :truncation_dim]\n",
    "\n",
    "\t# 2. Distance Calculation\n",
    "\tdist_output = Distance_Processors[distance_metric](data_truncated, data_truncated)\n",
    "\n",
    "\tprecision_matrix = None\n",
    "\tif distance_metric == \"mahalanobis\":\n",
    "\t\tdist_matrix, precision_matrix = dist_output\n",
    "\telse:\n",
    "\t\tdist_matrix = dist_output\n",
    "\n",
    "\t# 3. NN Indices (In-place modification to avoid copy overhead)\n",
    "\tnp.fill_diagonal(dist_matrix, float(\"inf\"))\n",
    "\tnn_indices = np.argmin(dist_matrix, axis=1)\n",
    "\tnp.fill_diagonal(dist_matrix, 0.0)\n",
    "\n",
    "\treturn {\n",
    "\t\t\"dist_matrix\": dist_matrix,\n",
    "\t\t\"vectors\": data_truncated,\n",
    "\t\t\"precision\": precision_matrix,\n",
    "\t\t\"semantic_data\": semantic_data,\n",
    "\t\t\"metric\": distance_metric,\n",
    "\t\t\"nn_indices\": nn_indices,\n",
    "\t}\n",
    "\n",
    "\n",
    "def prepareModelArtifacts(\n",
    "\tdata_set, vector_keys, truncation_dim=256, distance_metric=\"mahalanobis\", debug=True\n",
    "):\n",
    "\tsemantic_data = list(data_set.keys())\n",
    "\tmodel_artifacts = {}\n",
    "\traw_vectors = {}\n",
    "\tfor key in vector_keys:\n",
    "\t\traw_vectors[key] = [data_set[s][key] for s in semantic_data]\n",
    "\texecutor = concurrent.futures.ThreadPoolExecutor(max_workers=len(vector_keys))\n",
    "\n",
    "\tfutures = dict()\n",
    "\tfor key in vector_keys:\n",
    "\t\tif debug:\n",
    "\t\t\tprint(f\"Processing {key}...\")\n",
    "\n",
    "\t\tfutures[key] = executor.submit(\n",
    "\t\t\t_prepareModelArtifact,\n",
    "\t\t\traw_vectors[key],\n",
    "\t\t\tsemantic_data,\n",
    "\t\t\ttruncation_dim,\n",
    "\t\t\tdistance_metric,\n",
    "\t\t\tdebug,\n",
    "\t\t)\n",
    "\texecutor.shutdown(wait=True)\n",
    "\tfor key in vector_keys:\n",
    "\t\tmodel_artifacts[key] = futures[key].result()\n",
    "\treturn model_artifacts\n",
    "\n",
    "\n",
    "def getGroupsFromLabels(labels):\n",
    "\tgroups = {}\n",
    "\tfor idx, label in enumerate(labels):\n",
    "\t\tgroups.setdefault(label, []).append(idx)\n",
    "\treturn [g for g in groups.values() if len(g) > 1]\n",
    "\n",
    "\n",
    "def getNNPairsFromGroups(groups, nn_indices):\n",
    "\tpairs = set()\n",
    "\tfor group in groups:\n",
    "\t\tif len(group) < 2:\n",
    "\t\t\tcontinue\n",
    "\n",
    "\t\tgroup_set = set(group)\n",
    "\t\tfor idx in group:\n",
    "\t\t\tnn_idx = nn_indices[idx]\n",
    "\t\t\tif nn_idx in group_set:\n",
    "\t\t\t\tpairs.add(tuple(sorted((idx, nn_idx))))\n",
    "\treturn pairs\n",
    "\n",
    "\n",
    "def clusterAndGetArtifacts(dist_matrix, threshold):\n",
    "\tmodel = AgglomerativeClustering(\n",
    "\t\tn_clusters=None,\n",
    "\t\tdistance_threshold=threshold,\n",
    "\t\tmetric=\"precomputed\",\n",
    "\t\tlinkage=\"complete\",\n",
    "\t)\n",
    "\tlabels = model.fit_predict(dist_matrix)\n",
    "\treturn getGroupsFromLabels(labels), labels\n",
    "\n",
    "\n",
    "def calculateNTrue(labels_array, target_pairs):\n",
    "\tif not target_pairs or labels_array is None:\n",
    "\t\treturn 0\n",
    "\n",
    "\tinvolved_indices = {idx for pair in target_pairs for idx in pair}\n",
    "\n",
    "\tif not involved_indices:\n",
    "\t\treturn 0\n",
    "\n",
    "\treturn len({labels_array[idx] for idx in involved_indices})\n",
    "\n",
    "\n",
    "def getPairsFromLablesCombinations(labels):\n",
    "\t\"\"\"\n",
    "\tConverts cluster labels into a Set of unique pairs (indices).\n",
    "\tReturns: set of tuples {(min_id, max_id), ...}\n",
    "\t\"\"\"\n",
    "\tgroups = {}\n",
    "\tfor idx, label in enumerate(labels):\n",
    "\t\tgroups.setdefault(label, []).append(idx)\n",
    "\n",
    "\tpairs = set()\n",
    "\t# Group by label\n",
    "\tfor label, indices in groups.items():\n",
    "\t\tif len(indices) > 1:\n",
    "\t\t\t# Generate all unique pairs in this cluster\n",
    "\t\t\tfor p in combinations(sorted(indices), 2):\n",
    "\t\t\t\tpairs.add(p)\n",
    "\treturn pairs\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. New Functionality: Noise Generation & Stability\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "\n",
    "def generateDensityBasedNoise(vectors, nn_indices, k=1):\n",
    "\t\"\"\"\n",
    "\tGenerates noise vectors where the standard deviation for each point\n",
    "\tis exactly the distance to its k-th nearest neighbor.\n",
    "\n",
    "\tsigma_i = distance(i, NN_k)\n",
    "\t\"\"\"\n",
    "\t# 1. Get the indices of the k-th neighbor for every point\n",
    "\t# nn_indices shape is (N, >k). We grab the column corresponding to k.\n",
    "\t# (assuming column 0 is the point itself if included, but argmin usually returns OTHER)\n",
    "\t# If nn_indices comes from argmin on dist_matrix with diag=inf, it is rank 1 (N,)\n",
    "\t# If it is a matrix of neighbors, we select column k.\n",
    "\n",
    "\tif nn_indices.ndim == 1:\n",
    "\t\ttarget_neighbor_indices = nn_indices\t# Fallback to 1st NN if only 1 stored\n",
    "\telse:\n",
    "\t\ttarget_neighbor_indices = nn_indices[:, k]\n",
    "\n",
    "\t# 2. Extract vectors\n",
    "\tneighbor_vectors = vectors[target_neighbor_indices]\n",
    "\n",
    "\t# 3. Calculate distance (Local Sigma)\n",
    "\t# We calculate raw Euclidean magnitude based on NN proximity.\n",
    "\tlocal_sigmas = np.linalg.norm(vectors - neighbor_vectors, axis=1, keepdims=True)\n",
    "\n",
    "\t# Safety: Ensure no zero sigma (duplicates)\n",
    "\tlocal_sigmas[local_sigmas == 0] = 1e-9\n",
    "\n",
    "\t# 4. Generate Noise\n",
    "\t# N(0, sigma_i^2)\n",
    "\tnoise = np.random.normal(0, 1, size=vectors.shape) * local_sigmas\n",
    "\n",
    "\treturn noise\n",
    "\n",
    "\n",
    "def runStabilityTest(\n",
    "\tartifacts,\n",
    "\toptimal_taus,\n",
    "\tn_iterations=200,\n",
    "\tk_neighbor=1,\n",
    "\tactive_tests=[\"NN\", \"Combinations\"],\n",
    "\tconsensus_pairs=None,\n",
    "):\n",
    "\t\"\"\"\n",
    "\tRuns noise injection iterations and tracks cluster stability and ACGC metrics.\n",
    "\n",
    "\tArgs:\n",
    "\t    active_tests: List of strings. Options: \"NN\", \"Combinations\".\n",
    "\t    consensus_pairs: (Set of tuples, optional) The \"P_True\" set from findConsensusStructure.\n",
    "\t                     If provided, the ACGC component (N_Target) is calculated against this.\n",
    "\t                     If None, it is calculated against the model's own clean pairs.\n",
    "\tReturns:\n",
    "\t    plot_payload: Dict of data arrays.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Data structure for the plotter:\n",
    "\tplot_payload = {}\n",
    "\n",
    "\tprint(f\"--- Starting Stability Test ({n_iterations} iterations, k={k_neighbor}) ---\")\n",
    "\tprint(f\"Modes: {active_tests}\")\n",
    "\n",
    "\tfor key, art in artifacts.items():\n",
    "\t\tprint(f\"Processing Model: {key}\")\n",
    "\n",
    "\t\t# 1. Establish Clean Baseline\n",
    "\t\ttau = optimal_taus[key]\n",
    "\t\tclean_groups, clean_labels = clusterAndGetArtifacts(art[\"dist_matrix\"], tau)\n",
    "\n",
    "\t\t# Pre-compute baselines for Stability (Retention)\n",
    "\t\tclean_nn_pairs = None\n",
    "\t\tclean_comb_pairs = None\n",
    "\n",
    "\t\t# Determine the target for the ACGC Metric (N_Target)\n",
    "\t\t# If global consensus is provided, use that. Otherwise use local clean pairs.\n",
    "\t\ttarget_acgc_pairs = (\n",
    "\t\t\tconsensus_pairs\n",
    "\t\t\tif consensus_pairs is not None\n",
    "\t\t\telse getNNPairsFromGroups(clean_groups, art[\"nn_indices\"])\n",
    "\t\t)\n",
    "\n",
    "\t\tif \"NN\" in active_tests:\n",
    "\t\t\tclean_nn_pairs = getNNPairsFromGroups(clean_groups, art[\"nn_indices\"])\n",
    "\n",
    "\t\tif \"Combinations\" in active_tests:\n",
    "\t\t\tclean_comb_pairs = getPairsFromLablesCombinations(clean_labels)\n",
    "\n",
    "\t\t# Metric Logs\n",
    "\t\tnn_jaccard_scores = []\n",
    "\t\tcomb_jaccard_scores = []\n",
    "\t\tacgc_scores = []\t# This tracks N_True (Number of groups the target pairs fall into)\n",
    "\n",
    "\t\t# 2. Iteration Loop\n",
    "\t\tfor i in range(n_iterations):\n",
    "\t\t\t# A. Generate Noise based on Density\n",
    "\t\t\tnoise = generateDensityBasedNoise(art[\"vectors\"], art[\"nn_indices\"], k=k_neighbor)\n",
    "\t\t\tnoisy_vectors = art[\"vectors\"] + noise\n",
    "\n",
    "\t\t\t# B. Calculate Distances\n",
    "\t\t\t# (Reuse precision matrix if Mahalanobis to maintain sensor geometry)\n",
    "\t\t\tif art[\"metric\"] == \"mahalanobis\":\n",
    "\t\t\t\tnorms = np.linalg.norm(noisy_vectors, axis=1, keepdims=True)\n",
    "\t\t\t\tcleaned_v = noisy_vectors / (norms + 1e-10)\n",
    "\t\t\t\td_matrix = cdist(cleaned_v, cleaned_v, metric=\"mahalanobis\", VI=art[\"precision\"])\n",
    "\t\t\telse:\n",
    "\t\t\t\td_matrix = Distance_Processors[art[\"metric\"]](noisy_vectors, noisy_vectors)\n",
    "\n",
    "\t\t\tnp.fill_diagonal(d_matrix, 0.0)\n",
    "\n",
    "\t\t\t# C. Cluster\n",
    "\t\t\tgroups, labels = clusterAndGetArtifacts(d_matrix, tau)\n",
    "\n",
    "\t\t\t# D. Metric 1: ACGC Component (N_Target)\n",
    "\t\t\t# \"How many groups do the True Pairs span?\"\n",
    "\t\t\tn_target_val = calculateNTrue(labels, target_acgc_pairs)\n",
    "\t\t\tacgc_scores.append(n_target_val)\n",
    "\n",
    "\t\t\t# E. Metric 2: Stability (Jaccard vs Clean) - NN\n",
    "\t\t\tif \"NN\" in active_tests:\n",
    "\t\t\t\tcurrent_nn = getNNPairsFromGroups(groups, art[\"nn_indices\"])\n",
    "\t\t\t\tif clean_nn_pairs:\n",
    "\t\t\t\t\tscore = len(current_nn.intersection(clean_nn_pairs)) / len(\n",
    "\t\t\t\t\t\tcurrent_nn.union(clean_nn_pairs)\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tscore = 0 if current_nn else 1.0\n",
    "\t\t\t\tnn_jaccard_scores.append(score)\n",
    "\n",
    "\t\t\t# F. Metric 3: Stability (Jaccard vs Clean) - Combinations\n",
    "\t\t\tif \"Combinations\" in active_tests:\n",
    "\t\t\t\tcurrent_comb = getPairsFromLablesCombinations(labels)\n",
    "\t\t\t\tif clean_comb_pairs:\n",
    "\t\t\t\t\tscore = len(current_comb.intersection(clean_comb_pairs)) / len(\n",
    "\t\t\t\t\t\tcurrent_comb.union(clean_comb_pairs)\n",
    "\t\t\t\t\t)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tscore = 0 if current_comb else 1.0\n",
    "\t\t\t\tcomb_jaccard_scores.append(score)\n",
    "\n",
    "\t\t# Store in payload\n",
    "\t\tplot_payload[f\"{key} (ACGC_N_Target)\"] = acgc_scores\n",
    "\n",
    "\t\tif \"NN\" in active_tests:\n",
    "\t\t\tplot_payload[f\"{key} (NN_Stability)\"] = nn_jaccard_scores\n",
    "\t\tif \"Combinations\" in active_tests:\n",
    "\t\t\tplot_payload[f\"{key} (Comb_Stability)\"] = comb_jaccard_scores\n",
    "\n",
    "\treturn plot_payload\n",
    "\n",
    "\n",
    "def plotNoiseStability(\n",
    "\tdata_dict, title=\"Cluster Stability & ACGC under Density-Based Noise\"\n",
    "):\n",
    "\t\"\"\"\n",
    "\tPlots the stability traces with interactive filtering.\n",
    "\n",
    "\tArgs:\n",
    "\t    data_dict: { \"Method_Name\": [val1, val2, ... val200] }\n",
    "\t\"\"\"\n",
    "\tfig = go.Figure()\n",
    "\n",
    "\tkeys = list(data_dict.keys())\n",
    "\tif not keys:\n",
    "\t\tprint(\"No data to plot.\")\n",
    "\t\treturn\n",
    "\n",
    "\t# Add all traces\n",
    "\tfor key in keys:\n",
    "\t\ty_data = data_dict[key]\n",
    "\t\tx_data = list(range(len(y_data)))\n",
    "\n",
    "\t\t# Determine stats for the legend\n",
    "\t\tavg = np.mean(y_data)\n",
    "\t\tstd = np.std(y_data)\n",
    "\n",
    "\t\tfig.add_trace(\n",
    "\t\t\tgo.Scatter(\n",
    "\t\t\t\tx=x_data, y=y_data, mode=\"lines\", name=f\"{key} (μ={avg:.2f}, σ={std:.3f})\", opacity=0.8\n",
    "\t\t\t)\n",
    "\t\t)\n",
    "\n",
    "\t# --- Create Interactive Buttons (Filters) ---\n",
    "\tbuttons = []\n",
    "\n",
    "\t# 1. Button: Show All\n",
    "\tbuttons.append(\n",
    "\t\tdict(label=\"All\", method=\"update\", args=[{\"visible\": [True] * len(keys)}])\n",
    "\t)\n",
    "\n",
    "\t# 2. Button: ACGC Only\n",
    "\tis_acgc = [\"(ACGC_N_Target)\" in k for k in keys]\n",
    "\tif any(is_acgc):\n",
    "\t\tbuttons.append(\n",
    "\t\t\tdict(label=\"ACGC (N_Target)\", method=\"update\", args=[{\"visible\": is_acgc}])\n",
    "\t\t)\n",
    "\n",
    "\t# 3. Button: NN Stability\n",
    "\tis_nn = [\"(NN_Stability)\" in k for k in keys]\n",
    "\tif any(is_nn):\n",
    "\t\tbuttons.append(dict(label=\"NN Stability\", method=\"update\", args=[{\"visible\": is_nn}]))\n",
    "\n",
    "\t# 4. Button: Combinations Stability\n",
    "\tis_comb = [\"(Comb_Stability)\" in k for k in keys]\n",
    "\tif any(is_comb):\n",
    "\t\tbuttons.append(\n",
    "\t\t\tdict(label=\"Comb Stability\", method=\"update\", args=[{\"visible\": is_comb}])\n",
    "\t\t)\n",
    "\n",
    "\tfig.update_layout(\n",
    "\t\ttitle=title,\n",
    "\t\txaxis_title=\"Iteration\",\n",
    "\t\tyaxis_title=\"Metric Value\",\n",
    "\t\tupdatemenus=[\n",
    "\t\t\tdict(\n",
    "\t\t\t\ttype=\"buttons\", direction=\"left\", x=1.0, y=1.1, showactive=True, buttons=buttons\n",
    "\t\t\t)\n",
    "\t\t],\n",
    "\t\thovermode=\"x unified\",\n",
    "\t)\n",
    "\n",
    "\tfig.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Usage Example\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Note: This block assumes 'artifacts' and 'consensus_ACGC' are present in the scope.\n",
    "# In a real script, run 'prepareModelArtifacts' and 'findConsensusStructure' first.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\t# Example Configuration\n",
    "\t# We use the global 'P_true' from ACGC as the target to see if noise maintains the consensus.\n",
    "\n",
    "\t# Assuming 'consensus_ACGC' was calculated previously as per your snippet:\n",
    "\t# global_consensus_pairs = consensus_ACGC[\"P_true\"]\n",
    "\t# optimal_taus = consensus_ACGC[\"optimal_taus\"]\n",
    "\n",
    "\t# Mock vars for standalone execution safety (Replace with actuals)\n",
    "\tglobal_consensus_pairs = None\n",
    "\toptimal_taus_mock = (\n",
    "\t\t{k: 0.5 for k in artifacts.keys()} if \"artifacts\" in locals() else {}\n",
    "\t)\n",
    "\n",
    "\tif \"artifacts\" in locals() and \"consensus_ACGC\" in locals():\n",
    "\n",
    "\t\t# Run Phase 1: Stability with NN only + ACGC component\n",
    "\t\tstability_data = runStabilityTest(\n",
    "\t\t\tartifacts,\n",
    "\t\t\tconsensus_ACGC[\"optimal_taus\"],\n",
    "\t\t\tn_iterations=200,\n",
    "\t\t\tk_neighbor=1,\n",
    "\t\t\tactive_tests=[\"NN\"],\t# Start with NN as requested\n",
    "\t\t\tconsensus_pairs=consensus_ACGC[\"P_true\"],\n",
    "\t\t)\n",
    "\n",
    "\t\t# Plot\n",
    "\t\tplotNoiseStability(stability_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
